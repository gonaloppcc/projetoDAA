{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SOURCE = '../training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = '../test_data.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from pandas import DataFrame\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = train_df.drop(['incidents'], axis=1)\n",
    "target = train_df['incidents'].map({'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4})\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=1234)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      city_name magnitude_of_delay  delay_in_seconds  \\\n3700  Guimaraes          UNDEFINED                 0   \n894   Guimaraes          UNDEFINED                 0   \n2322  Guimaraes          UNDEFINED                 0   \n4592  Guimaraes          UNDEFINED                 0   \n3711  Guimaraes          UNDEFINED                 0   \n...         ...                ...               ...   \n664   Guimaraes          UNDEFINED                 0   \n3276  Guimaraes          UNDEFINED                 0   \n1318  Guimaraes          UNDEFINED                 0   \n723   Guimaraes          UNDEFINED                 0   \n2863  Guimaraes          UNDEFINED               767   \n\n                                affected_roads       record_date luminosity  \\\n3700                  N101,N101,N101,N101,N101  2021-11-18 22:00       DARK   \n894                   N101,N101,N101,N101,N101  2021-09-27 20:00       DARK   \n2322                  N101,N101,N101,N101,N101  2021-11-17 23:00       DARK   \n4592                                 N101,N101  2021-12-31 02:00       DARK   \n3711                  N101,N101,N101,N101,N101  2021-11-13 02:00       DARK   \n...                                        ...               ...        ...   \n664                  N101,N101,N101,N101,N101,  2021-06-25 22:00       DARK   \n3276                                         ,  2021-12-26 02:00       DARK   \n1318                  N101,N101,N101,N101,N101  2021-12-04 03:00       DARK   \n723                   N101,N101,N101,N101,N101  2021-10-14 00:00       DARK   \n2863  N101,N101,N101,N101,N101,N101,N101,N101,  2021-06-11 12:00      LIGHT   \n\n      avg_temperature  avg_atm_pressure  avg_humidity  avg_wind_speed  \\\n3700             11.0            1025.0          67.0             2.0   \n894              18.0            1023.0          93.0             0.0   \n2322             11.0            1024.0          63.0             2.0   \n4592              9.0            1023.0          74.0             2.0   \n3711              9.0            1019.0          74.0             1.0   \n...               ...               ...           ...             ...   \n664              19.0            1016.0          58.0             0.0   \n3276             12.0            1009.0          93.0             0.0   \n1318             11.0            1024.0          94.0             1.0   \n723              17.0            1019.0          32.0             2.0   \n2863             24.0            1014.0          28.0             2.0   \n\n      avg_precipitation   avg_rain  \n3700                0.0  Sem Chuva  \n894                 0.0  Sem Chuva  \n2322                0.0  Sem Chuva  \n4592                0.0  Sem Chuva  \n3711                0.0  Sem Chuva  \n...                 ...        ...  \n664                 0.0  Sem Chuva  \n3276                0.0  Sem Chuva  \n1318                0.0  Sem Chuva  \n723                 0.0  Sem Chuva  \n2863                0.0  Sem Chuva  \n\n[4000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city_name</th>\n      <th>magnitude_of_delay</th>\n      <th>delay_in_seconds</th>\n      <th>affected_roads</th>\n      <th>record_date</th>\n      <th>luminosity</th>\n      <th>avg_temperature</th>\n      <th>avg_atm_pressure</th>\n      <th>avg_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>avg_precipitation</th>\n      <th>avg_rain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3700</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-11-18 22:00</td>\n      <td>DARK</td>\n      <td>11.0</td>\n      <td>1025.0</td>\n      <td>67.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-09-27 20:00</td>\n      <td>DARK</td>\n      <td>18.0</td>\n      <td>1023.0</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2322</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-11-17 23:00</td>\n      <td>DARK</td>\n      <td>11.0</td>\n      <td>1024.0</td>\n      <td>63.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>4592</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101</td>\n      <td>2021-12-31 02:00</td>\n      <td>DARK</td>\n      <td>9.0</td>\n      <td>1023.0</td>\n      <td>74.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>3711</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-11-13 02:00</td>\n      <td>DARK</td>\n      <td>9.0</td>\n      <td>1019.0</td>\n      <td>74.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101,</td>\n      <td>2021-06-25 22:00</td>\n      <td>DARK</td>\n      <td>19.0</td>\n      <td>1016.0</td>\n      <td>58.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>3276</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>,</td>\n      <td>2021-12-26 02:00</td>\n      <td>DARK</td>\n      <td>12.0</td>\n      <td>1009.0</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>1318</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-12-04 03:00</td>\n      <td>DARK</td>\n      <td>11.0</td>\n      <td>1024.0</td>\n      <td>94.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>723</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-10-14 00:00</td>\n      <td>DARK</td>\n      <td>17.0</td>\n      <td>1019.0</td>\n      <td>32.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2863</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>767</td>\n      <td>N101,N101,N101,N101,N101,N101,N101,N101,</td>\n      <td>2021-06-11 12:00</td>\n      <td>LIGHT</td>\n      <td>24.0</td>\n      <td>1014.0</td>\n      <td>28.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "3700    0\n894     0\n2322    0\n4592    0\n3711    0\n       ..\n664     1\n3276    0\n1318    1\n723     0\n2863    4\nName: incidents, Length: 4000, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 5, 6)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_mask = (train_df.dtypes=='object')\n",
    "categorical_columns = train_df.columns[categorical_mask].tolist()\n",
    "num_cols = train_df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "oe_cols = [c for c in categorical_columns if train_df[c].nunique()>5]\n",
    "ohe_cols = [c for c in categorical_columns if train_df[c].nunique()<=5]\n",
    "len(oe_cols), len(ohe_cols), len(num_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "ohe_unique_list = [train_df[c].unique().tolist() for c in ohe_cols]\n",
    "oe_unique_list = [train_df[c].unique().tolist() for c in oe_cols]\n",
    "ohe = OneHotEncoder(categories=ohe_unique_list)\n",
    "oe = OrdinalEncoder(categories=oe_unique_list)\n",
    "imp = SimpleImputer(strategy='constant', fill_value=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_classif\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (oe, oe_cols),\n",
    "    (ohe, ohe_cols),\n",
    "    (imp, num_cols),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "estimator = XGBClassifier(learning_rate=0.05, max_depth=3, n_estimators=2500, random_state=1234)\n",
    "fs = SelectKBest(score_func=f_classif, k=5)\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "steps = [\n",
    "    ('preprocess', preprocess),\n",
    "    ('select', fs),\n",
    "    ('clf', estimator)\n",
    "]\n",
    "pipeline = Pipeline(steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'incidents'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\utils\\__init__.py:416\u001B[0m, in \u001B[0;36m_get_column_indices\u001B[1;34m(X, key)\u001B[0m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[1;32m--> 416\u001B[0m     col_idx \u001B[38;5;241m=\u001B[39m \u001B[43mall_columns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col_idx, numbers\u001B[38;5;241m.\u001B[39mIntegral):\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'incidents'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[1;32m----> 3\u001B[0m pipeline\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      4\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      5\u001B[0m pred_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m: y_test,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m'\u001B[39m: y_pred})\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py:378\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m\"\"\"Fit the model.\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \n\u001B[0;32m    354\u001B[0m \u001B[38;5;124;03mFit all the transformers one after the other and transform the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;124;03m    Pipeline with fitted steps.\u001B[39;00m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    377\u001B[0m fit_params_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_fit_params(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m--> 378\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_steps)\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py:336\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[1;34m(self, X, y, **fit_params_steps)\u001B[0m\n\u001B[0;32m    334\u001B[0m     cloned_transformer \u001B[38;5;241m=\u001B[39m clone(transformer)\n\u001B[0;32m    335\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[1;32m--> 336\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m fit_transform_one_cached(\n\u001B[0;32m    337\u001B[0m     cloned_transformer,\n\u001B[0;32m    338\u001B[0m     X,\n\u001B[0;32m    339\u001B[0m     y,\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    341\u001B[0m     message_clsname\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    342\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(step_idx),\n\u001B[0;32m    343\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_steps[name],\n\u001B[0;32m    344\u001B[0m )\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\joblib\\memory.py:349\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py:870\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 870\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit_transform(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    872\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:687\u001B[0m, in \u001B[0;36mColumnTransformer.fit_transform\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    685\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_n_features(X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    686\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_transformers()\n\u001B[1;32m--> 687\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_column_callables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_remainder(X)\n\u001B[0;32m    690\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:374\u001B[0m, in \u001B[0;36mColumnTransformer._validate_column_callables\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    372\u001B[0m         columns \u001B[38;5;241m=\u001B[39m columns(X)\n\u001B[0;32m    373\u001B[0m     all_columns\u001B[38;5;241m.\u001B[39mappend(columns)\n\u001B[1;32m--> 374\u001B[0m     transformer_to_input_indices[name] \u001B[38;5;241m=\u001B[39m \u001B[43m_get_column_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_columns \u001B[38;5;241m=\u001B[39m all_columns\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformer_to_input_indices \u001B[38;5;241m=\u001B[39m transformer_to_input_indices\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\utils\\__init__.py:424\u001B[0m, in \u001B[0;36m_get_column_indices\u001B[1;34m(X, key)\u001B[0m\n\u001B[0;32m    421\u001B[0m             column_indices\u001B[38;5;241m.\u001B[39mappend(col_idx)\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 424\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA given column is not a column of the dataframe\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m column_indices\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "pred_df = pd.DataFrame({'y': y_test,'y_pred': y_pred})\n",
    "gini = 2*accuracy_score(y_test, y_pred)-1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
