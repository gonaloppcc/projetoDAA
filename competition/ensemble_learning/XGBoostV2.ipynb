{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementação do Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from pandas import DataFrame\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "TRAINING_DATASET_SOURCE = '../training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = '../test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definição dos dados de teste e de treino"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df['incidents'].value_counts())\n",
    "\n",
    "incidents_count = train_df['incidents'].value_counts()\n",
    "\n",
    "max_count = incidents_count.max()\n",
    "print('Max value count:', max_count)\n",
    "\n",
    "df_classes = []\n",
    "for category, counts in zip(incidents_count.index, incidents_count):\n",
    "    #print(category, counts)\n",
    "    df_classes.append(train_df[train_df['incidents'] == category])\n",
    "\n",
    "df_classes_over = []\n",
    "\n",
    "for category in df_classes:\n",
    "    df_classes_over.append(category.sample(max_count, replace=True))\n",
    "\n",
    "df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "print(df_test_over['incidents'].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = df_test_over.drop(['incidents'], axis=1)\n",
    "target = df_test_over['incidents']\n",
    "\n",
    "all_features = features.columns.tolist()\n",
    "\n",
    "features[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtenção das features numericas e categoricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_to_numerical = {\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 1,\n",
    "        'DARK': 2\n",
    "    },\n",
    "    'avg_rain': {\n",
    "        'Sem Chuva': 0,\n",
    "        'chuva fraca': 1,\n",
    "        'chuva moderada': 2,\n",
    "        'chuva forte': 3,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def decision_tree_data_preparation(df: DataFrame) -> DataFrame:\n",
    "    prep_df = df.copy()\n",
    "\n",
    "    dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay']\n",
    "\n",
    "    numerical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                          dtype.kind in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    numerical_features = ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "    #assert numerical_features == ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "\n",
    "    categorical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                            dtype.kind not in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    prep_df = prep_df.drop(dropped_columns, axis=1)\n",
    "    prep_df.drop_duplicates()\n",
    "\n",
    "    ### Converter as features categoricas em numericas\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "    record_date = pd.DatetimeIndex(prep_df['record_date'])\n",
    "\n",
    "    prep_df['hour'] = record_date.hour\n",
    "    prep_df['day'] = record_date.day\n",
    "    prep_df['month'] = record_date.month\n",
    "    prep_df['weekday'] = record_date.weekday\n",
    "\n",
    "    prep_df.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "    #train_df['affected_roads'] = train_df['affected_roads'].fillna(train_df['affected_roads'].mode().iloc[0])\n",
    "\n",
    "    num_affected_roads = []\n",
    "    for line in prep_df['affected_roads']:\n",
    "        unique_roads = set(str(line).split(','))\n",
    "        valid_roads = [elem for elem in unique_roads if elem != '']\n",
    "        count = len(valid_roads)\n",
    "        num_affected_roads.append(count)\n",
    "\n",
    "    prep_df['num_affected_roads'] = num_affected_roads\n",
    "\n",
    "    ### Ao analisar o resultado pós-tratamento, verificámos que a feature 'affected_roads' tinha alta correlação com 'delay_in_minutes'\n",
    "    prep_df.drop(columns=['affected_roads'], inplace=True)\n",
    "\n",
    "    ### Converter a feature 'delay_in_seconds' para 'delay_in_minutes' de modo a reduzir o intervalo de valores\n",
    "    delay_in_minutes = prep_df['delay_in_seconds'].map(lambda seconds: seconds / 60)\n",
    "\n",
    "    prep_df.drop(columns=['delay_in_seconds'], inplace=True)\n",
    "    prep_df['delay_in_minutes'] = delay_in_minutes\n",
    "\n",
    "    ### Limites superior e inferior (sem outliers) dos diagramas de caixa\n",
    "    #numerical_features.remove('delay_in_seconds')\n",
    "    #numerical_features.append('delay_in_minutes')\n",
    "\n",
    "    return prep_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Divisão dos dados em dados de teste e treino"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_num = pd.DataFrame(target.map({'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}))\n",
    "target_num.reset_index(drop=True, inplace=True)\n",
    "target_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(decision_tree_data_preparation(features), target_num, test_size=0.3,\n",
    "                                                    random_state=2000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "boost_model = XGBClassifier(n_estimators=500, early_stopping_rounds=5, random_state=22)\n",
    "boost_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Train accuracy:\", boost_model.score(X_train, y_train))\n",
    "\n",
    "predictions = boost_model.predict(X_test)\n",
    "print(\"Test accuracy: \" + str(accuracy_score(predictions, y_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gonca\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross Validation results: {'mean_fit_time': array([ 9.25274947, 17.09005015,  7.62104981,  9.09464887,  8.52954987,\n",
      "        7.31574947,  5.07199948,  7.87439961, 10.58844969,  9.39970008,\n",
      "       21.45329956,  8.7837495 , 13.69439992,  6.83869972, 11.10589986,\n",
      "        8.62279927,  8.38169988, 10.62974981, 20.69694959,  4.10169971,\n",
      "        9.73744975, 16.9145492 , 10.56314945,  6.81909953, 11.16275001,\n",
      "        5.48114932, 11.95399995, 12.10465012,  9.8977995 ,  5.72714951,\n",
      "        9.92684965, 11.63169951, 12.60144968, 12.29044933,  9.44079947,\n",
      "        8.7102495 , 10.77184982, 12.11054993, 13.84569966,  7.61399953,\n",
      "       12.11519952,  6.77154949,  8.45434974, 17.69334953,  9.5424492 ,\n",
      "       19.00139964, 15.50444981, 15.49119928, 14.45489925,  7.48679872]), 'std_fit_time': array([0.25842747, 0.25842512, 0.25009331, 0.11348471, 0.12692124,\n",
      "       0.08593316, 0.09772172, 0.05741843, 0.16162266, 0.14207715,\n",
      "       0.41061408, 0.14704468, 0.09246712, 0.03716182, 0.2596253 ,\n",
      "       0.09663162, 0.35351465, 0.16939411, 0.19255991, 0.11937582,\n",
      "       0.18763398, 0.22062936, 0.12111791, 0.15985389, 0.29450633,\n",
      "       0.1263234 , 0.12605392, 0.34093211, 0.35804394, 0.25640025,\n",
      "       0.14523564, 0.12340484, 0.44140158, 0.39894637, 0.24585447,\n",
      "       0.21704408, 0.12939733, 0.28376098, 0.28342012, 0.36663385,\n",
      "       0.64901517, 0.06286415, 0.25621277, 0.56629779, 0.1874632 ,\n",
      "       0.2935496 , 0.20938856, 1.15973531, 0.18811333, 0.55543544]), 'mean_score_time': array([0.00770025, 0.00754998, 0.00490044, 0.00550001, 0.00535022,\n",
      "       0.0050503 , 0.00415061, 0.00480024, 0.00605091, 0.00585008,\n",
      "       0.00890033, 0.00480049, 0.00705003, 0.00480026, 0.00560023,\n",
      "       0.00550029, 0.00495046, 0.00600034, 0.00835016, 0.00410011,\n",
      "       0.00605031, 0.00685024, 0.00600086, 0.00455022, 0.00525019,\n",
      "       0.00455018, 0.00515018, 0.00600023, 0.00519993, 0.0045006 ,\n",
      "       0.00525062, 0.00610032, 0.00670054, 0.00585028, 0.00500047,\n",
      "       0.00485015, 0.00625042, 0.00640016, 0.00655032, 0.00520036,\n",
      "       0.00685019, 0.0046505 , 0.0056502 , 0.00750047, 0.00555025,\n",
      "       0.00770055, 0.00690063, 0.01094995, 0.02110121, 0.00530064]), 'std_score_time': array([0.002917  , 0.00111707, 0.00069993, 0.00067111, 0.00047694,\n",
      "       0.00021778, 0.0003572 , 0.00059964, 0.00021768, 0.00065367,\n",
      "       0.00083019, 0.00059994, 0.00058951, 0.00074862, 0.00073499,\n",
      "       0.0008062 , 0.00049783, 0.00063249, 0.00057219, 0.00053854,\n",
      "       0.00038399, 0.00101359, 0.00063249, 0.0006691 , 0.00043329,\n",
      "       0.0007398 , 0.00035738, 0.00044745, 0.0006782 , 0.00049982,\n",
      "       0.000536  , 0.00029988, 0.0005566 , 0.00057234, 0.00063228,\n",
      "       0.00072656, 0.0005361 , 0.00048989, 0.00066912, 0.00040059,\n",
      "       0.00123592, 0.00047672, 0.00065415, 0.00059174, 0.00049793,\n",
      "       0.00064066, 0.00104405, 0.0128668 , 0.04518107, 0.00434874]), 'param_colsample_bytree': masked_array(data=[0.6876599021161582, 0.541552367645959,\n",
      "                   0.6886375314814827, 0.801710379580281,\n",
      "                   0.935717709073729, 0.8731161083152137,\n",
      "                   0.8022443438399605, 0.8755815523538177,\n",
      "                   0.6343228826388702, 0.5432775172004578,\n",
      "                   0.8054759898229509, 0.7546604123588869,\n",
      "                   0.5460504929725216, 0.8444682969983919,\n",
      "                   0.7639497682258969, 0.6699129535179926,\n",
      "                   0.83786544641127, 0.6214675512942618,\n",
      "                   0.7797630740941048, 0.6836615612425765,\n",
      "                   0.5688184201493129, 0.7805120521063112,\n",
      "                   0.5315366732146831, 0.5297000777249281,\n",
      "                   0.5775252585034524, 0.8870125769072996,\n",
      "                   0.6051301354589511, 0.8658477366736881,\n",
      "                   0.8885938345517429, 0.5690023150638085,\n",
      "                   0.5161997463693666, 0.5914819555974458,\n",
      "                   0.5225081386497092, 0.9018595454883287,\n",
      "                   0.7728482577439987, 0.5657147356947029,\n",
      "                   0.5595202735055288, 0.5729924796517298,\n",
      "                   0.7877573963959731, 0.8276052395312464,\n",
      "                   0.5062782078390187, 0.7504939346878203,\n",
      "                   0.5108457319237035, 0.9334681377983203,\n",
      "                   0.9265865950479564, 0.8985604372938782,\n",
      "                   0.8801305004264999, 0.6285734832803664,\n",
      "                   0.5982769544806656, 0.7447537558734758],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.7303244934421581, 0.1962602113776709,\n",
      "                   0.6952195003967595, 0.427304802367127,\n",
      "                   0.32342417815924285, 0.8396033593941836,\n",
      "                   0.421787878969053, 0.028288277344191808,\n",
      "                   0.45613450608610606, 0.9133701664788674,\n",
      "                   0.22162811600005905, 0.6239383177960557,\n",
      "                   0.4240559878195683, 0.055345728574653245,\n",
      "                   0.9134019152878835, 0.5484246942799851,\n",
      "                   0.7359979853504515, 0.9058862181960669,\n",
      "                   0.12474597295337518, 0.24702698024302772,\n",
      "                   0.5886339307357229, 0.025821242846556285,\n",
      "                   0.48247503800046254, 0.7654630526024664,\n",
      "                   0.40631328751303986, 0.5488310643416529,\n",
      "                   0.1015564416778033, 0.29976000273953574,\n",
      "                   0.7571216427371846, 0.9471903244000067,\n",
      "                   0.6643237716895042, 0.2623257445703234,\n",
      "                   0.7509555557358842, 0.7693487949563279,\n",
      "                   0.5788514370864813, 0.5187887387793378,\n",
      "                   0.7742416087544277, 0.36646368012067,\n",
      "                   0.5346703091237337, 0.532736629636422,\n",
      "                   0.24436208612142052, 0.9256063497662745,\n",
      "                   0.46200160835818516, 0.18395566668046437,\n",
      "                   0.8371154711707325, 0.5443773390705634,\n",
      "                   0.9153923187086492, 0.5002535226199277,\n",
      "                   0.25870020007610706, 0.20126026919431406],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[5, 5, 3, 5, 8, 8, 3, 5, 8, 5, 8, 3, 5, 5, 3, 5, 3, 8,\n",
      "                   8, 3, 8, 5, 5, 3, 3, 3, 3, 5, 3, 3, 3, 8, 8, 8, 3, 3,\n",
      "                   8, 8, 5, 8, 8, 3, 8, 5, 8, 8, 8, 5, 5, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[3, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 1, 3, 1, 3, 1, 3, 1,\n",
      "                   1, 1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 1, 3, 3, 1, 1, 1, 1,\n",
      "                   3, 1, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 3, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[283, 431, 306, 236, 151, 180, 193, 165, 254, 305, 429,\n",
      "                   340, 409, 152, 482, 207, 302, 302, 332, 165, 264, 367,\n",
      "                   291, 287, 446, 195, 452, 280, 360, 234, 426, 236, 378,\n",
      "                   325, 352, 356, 355, 255, 370, 171, 221, 264, 162, 444,\n",
      "                   223, 490, 445, 429, 319, 255],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.4027291235719791, 0.6771717138023499,\n",
      "                   0.3191713152385483, 0.8605211980728755,\n",
      "                   0.9055141763852883, 0.7151458628086398,\n",
      "                   0.7805506493771085, 0.762445011166602,\n",
      "                   0.6284669685067001, 0.31355687050920794,\n",
      "                   0.7090723845165503, 0.7898308520146518,\n",
      "                   0.6784203561765507, 0.9612163291935694,\n",
      "                   0.9244951104013166, 0.5434361018218545,\n",
      "                   0.5442288393844897, 0.7644090484729136,\n",
      "                   0.7048727300709923, 0.8409174027443038,\n",
      "                   0.9359746056438594, 0.6859274588385671,\n",
      "                   0.7877727130429301, 0.6632033131047314,\n",
      "                   0.47234774732213214, 0.49482318674714354,\n",
      "                   0.5574902684469006, 0.5715024508449202,\n",
      "                   0.5533331099297283, 0.7314302615753732,\n",
      "                   0.6976703233439594, 0.5597937306688278,\n",
      "                   0.987229648830642, 0.6404415776559222,\n",
      "                   0.37653524730966725, 0.6235067589986598,\n",
      "                   0.3667934740105933, 0.4354039978363294,\n",
      "                   0.5271622474951502, 0.952380448437786,\n",
      "                   0.9651232834729557, 0.4168661156521539,\n",
      "                   0.5764129290464883, 0.31506736369193855,\n",
      "                   0.652153134284152, 0.9151823890882909,\n",
      "                   0.8590225138064276, 0.9669817866045012,\n",
      "                   0.8705700390376154, 0.5941355760007925],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.6876599021161582, 'learning_rate': 0.7303244934421581, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 283, 'subsample': 0.4027291235719791}, {'colsample_bytree': 0.541552367645959, 'learning_rate': 0.1962602113776709, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 431, 'subsample': 0.6771717138023499}, {'colsample_bytree': 0.6886375314814827, 'learning_rate': 0.6952195003967595, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 306, 'subsample': 0.3191713152385483}, {'colsample_bytree': 0.801710379580281, 'learning_rate': 0.427304802367127, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 236, 'subsample': 0.8605211980728755}, {'colsample_bytree': 0.935717709073729, 'learning_rate': 0.32342417815924285, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 151, 'subsample': 0.9055141763852883}, {'colsample_bytree': 0.8731161083152137, 'learning_rate': 0.8396033593941836, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 180, 'subsample': 0.7151458628086398}, {'colsample_bytree': 0.8022443438399605, 'learning_rate': 0.421787878969053, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 193, 'subsample': 0.7805506493771085}, {'colsample_bytree': 0.8755815523538177, 'learning_rate': 0.028288277344191808, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 165, 'subsample': 0.762445011166602}, {'colsample_bytree': 0.6343228826388702, 'learning_rate': 0.45613450608610606, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 254, 'subsample': 0.6284669685067001}, {'colsample_bytree': 0.5432775172004578, 'learning_rate': 0.9133701664788674, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 305, 'subsample': 0.31355687050920794}, {'colsample_bytree': 0.8054759898229509, 'learning_rate': 0.22162811600005905, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 429, 'subsample': 0.7090723845165503}, {'colsample_bytree': 0.7546604123588869, 'learning_rate': 0.6239383177960557, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 340, 'subsample': 0.7898308520146518}, {'colsample_bytree': 0.5460504929725216, 'learning_rate': 0.4240559878195683, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 409, 'subsample': 0.6784203561765507}, {'colsample_bytree': 0.8444682969983919, 'learning_rate': 0.055345728574653245, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 152, 'subsample': 0.9612163291935694}, {'colsample_bytree': 0.7639497682258969, 'learning_rate': 0.9134019152878835, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 482, 'subsample': 0.9244951104013166}, {'colsample_bytree': 0.6699129535179926, 'learning_rate': 0.5484246942799851, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 207, 'subsample': 0.5434361018218545}, {'colsample_bytree': 0.83786544641127, 'learning_rate': 0.7359979853504515, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 302, 'subsample': 0.5442288393844897}, {'colsample_bytree': 0.6214675512942618, 'learning_rate': 0.9058862181960669, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 302, 'subsample': 0.7644090484729136}, {'colsample_bytree': 0.7797630740941048, 'learning_rate': 0.12474597295337518, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 332, 'subsample': 0.7048727300709923}, {'colsample_bytree': 0.6836615612425765, 'learning_rate': 0.24702698024302772, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 165, 'subsample': 0.8409174027443038}, {'colsample_bytree': 0.5688184201493129, 'learning_rate': 0.5886339307357229, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 264, 'subsample': 0.9359746056438594}, {'colsample_bytree': 0.7805120521063112, 'learning_rate': 0.025821242846556285, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 367, 'subsample': 0.6859274588385671}, {'colsample_bytree': 0.5315366732146831, 'learning_rate': 0.48247503800046254, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 291, 'subsample': 0.7877727130429301}, {'colsample_bytree': 0.5297000777249281, 'learning_rate': 0.7654630526024664, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 287, 'subsample': 0.6632033131047314}, {'colsample_bytree': 0.5775252585034524, 'learning_rate': 0.40631328751303986, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 446, 'subsample': 0.47234774732213214}, {'colsample_bytree': 0.8870125769072996, 'learning_rate': 0.5488310643416529, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 195, 'subsample': 0.49482318674714354}, {'colsample_bytree': 0.6051301354589511, 'learning_rate': 0.1015564416778033, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 452, 'subsample': 0.5574902684469006}, {'colsample_bytree': 0.8658477366736881, 'learning_rate': 0.29976000273953574, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 280, 'subsample': 0.5715024508449202}, {'colsample_bytree': 0.8885938345517429, 'learning_rate': 0.7571216427371846, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 360, 'subsample': 0.5533331099297283}, {'colsample_bytree': 0.5690023150638085, 'learning_rate': 0.9471903244000067, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 234, 'subsample': 0.7314302615753732}, {'colsample_bytree': 0.5161997463693666, 'learning_rate': 0.6643237716895042, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 426, 'subsample': 0.6976703233439594}, {'colsample_bytree': 0.5914819555974458, 'learning_rate': 0.2623257445703234, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 236, 'subsample': 0.5597937306688278}, {'colsample_bytree': 0.5225081386497092, 'learning_rate': 0.7509555557358842, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 378, 'subsample': 0.987229648830642}, {'colsample_bytree': 0.9018595454883287, 'learning_rate': 0.7693487949563279, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 325, 'subsample': 0.6404415776559222}, {'colsample_bytree': 0.7728482577439987, 'learning_rate': 0.5788514370864813, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 352, 'subsample': 0.37653524730966725}, {'colsample_bytree': 0.5657147356947029, 'learning_rate': 0.5187887387793378, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 356, 'subsample': 0.6235067589986598}, {'colsample_bytree': 0.5595202735055288, 'learning_rate': 0.7742416087544277, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 355, 'subsample': 0.3667934740105933}, {'colsample_bytree': 0.5729924796517298, 'learning_rate': 0.36646368012067, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 255, 'subsample': 0.4354039978363294}, {'colsample_bytree': 0.7877573963959731, 'learning_rate': 0.5346703091237337, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 370, 'subsample': 0.5271622474951502}, {'colsample_bytree': 0.8276052395312464, 'learning_rate': 0.532736629636422, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 171, 'subsample': 0.952380448437786}, {'colsample_bytree': 0.5062782078390187, 'learning_rate': 0.24436208612142052, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 221, 'subsample': 0.9651232834729557}, {'colsample_bytree': 0.7504939346878203, 'learning_rate': 0.9256063497662745, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 264, 'subsample': 0.4168661156521539}, {'colsample_bytree': 0.5108457319237035, 'learning_rate': 0.46200160835818516, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 162, 'subsample': 0.5764129290464883}, {'colsample_bytree': 0.9334681377983203, 'learning_rate': 0.18395566668046437, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 444, 'subsample': 0.31506736369193855}, {'colsample_bytree': 0.9265865950479564, 'learning_rate': 0.8371154711707325, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 223, 'subsample': 0.652153134284152}, {'colsample_bytree': 0.8985604372938782, 'learning_rate': 0.5443773390705634, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 490, 'subsample': 0.9151823890882909}, {'colsample_bytree': 0.8801305004264999, 'learning_rate': 0.9153923187086492, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 445, 'subsample': 0.8590225138064276}, {'colsample_bytree': 0.6285734832803664, 'learning_rate': 0.5002535226199277, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 429, 'subsample': 0.9669817866045012}, {'colsample_bytree': 0.5982769544806656, 'learning_rate': 0.25870020007610706, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 319, 'subsample': 0.8705700390376154}, {'colsample_bytree': 0.7447537558734758, 'learning_rate': 0.20126026919431406, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 255, 'subsample': 0.5941355760007925}], 'split0_test_score': array([0.98591549, 0.98873239, 0.98591549, 0.98873239, 0.98873239,\n",
      "       0.98873239, 0.9915493 , 0.93521127, 0.98873239, 0.98873239,\n",
      "       0.9915493 , 0.98873239, 0.98873239, 0.96619718, 0.9915493 ,\n",
      "       0.98873239, 0.98873239, 0.98873239, 0.9915493 , 0.98028169,\n",
      "       0.98873239, 0.96619718, 0.98873239, 0.98591549, 0.9915493 ,\n",
      "       0.9915493 , 0.96901408, 0.98873239, 0.98873239, 0.9915493 ,\n",
      "       0.98591549, 0.98873239, 0.98873239, 0.98873239, 0.98873239,\n",
      "       0.9915493 , 0.98309859, 0.98873239, 0.98873239, 0.9915493 ,\n",
      "       0.98873239, 0.98309859, 0.98873239, 0.98873239, 0.98873239,\n",
      "       0.9915493 , 0.9915493 , 0.98873239, 0.98873239, 0.98309859]), 'split1_test_score': array([0.98591549, 0.9915493 , 0.98591549, 0.98873239, 0.98873239,\n",
      "       0.9915493 , 0.98309859, 0.91830986, 0.9915493 , 0.98591549,\n",
      "       0.9915493 , 0.9915493 , 0.9915493 , 0.95774648, 0.98591549,\n",
      "       0.9915493 , 0.98028169, 0.98873239, 0.9915493 , 0.94647887,\n",
      "       0.9943662 , 0.95774648, 0.9915493 , 0.98873239, 0.98309859,\n",
      "       0.98591549, 0.94929577, 0.9915493 , 0.98873239, 0.9915493 ,\n",
      "       0.9915493 , 0.9915493 , 0.9915493 , 0.9971831 , 0.98873239,\n",
      "       0.98873239, 0.98028169, 0.9943662 , 0.9915493 , 0.9915493 ,\n",
      "       0.9915493 , 0.98873239, 0.98873239, 0.9915493 , 0.98591549,\n",
      "       0.9915493 , 0.9943662 , 0.9943662 , 0.9915493 , 0.95774648]), 'split2_test_score': array([0.98309859, 0.98591549, 0.98028169, 0.98309859, 0.98309859,\n",
      "       0.97746479, 0.98028169, 0.92112676, 0.97746479, 0.98309859,\n",
      "       0.98591549, 0.98028169, 0.98309859, 0.95211268, 0.98028169,\n",
      "       0.98591549, 0.97746479, 0.97746479, 0.98309859, 0.95211268,\n",
      "       0.97746479, 0.95492958, 0.98309859, 0.98028169, 0.98309859,\n",
      "       0.98309859, 0.95774648, 0.98309859, 0.97464789, 0.97746479,\n",
      "       0.98309859, 0.98309859, 0.98028169, 0.98309859, 0.98028169,\n",
      "       0.98028169, 0.98028169, 0.98309859, 0.97746479, 0.98309859,\n",
      "       0.98591549, 0.97746479, 0.98309859, 0.98028169, 0.98309859,\n",
      "       0.98591549, 0.98309859, 0.98591549, 0.98309859, 0.95211268]), 'split3_test_score': array([0.97183099, 0.96901408, 0.96338028, 0.97746479, 0.97746479,\n",
      "       0.98028169, 0.96901408, 0.92394366, 0.97464789, 0.96901408,\n",
      "       0.97183099, 0.97183099, 0.96901408, 0.95211268, 0.96619718,\n",
      "       0.97183099, 0.96901408, 0.97464789, 0.97183099, 0.94929577,\n",
      "       0.97183099, 0.94647887, 0.97183099, 0.96901408, 0.96901408,\n",
      "       0.96901408, 0.95492958, 0.97183099, 0.96901408, 0.97183099,\n",
      "       0.96619718, 0.97183099, 0.96901408, 0.97183099, 0.96619718,\n",
      "       0.97464789, 0.96619718, 0.97183099, 0.96901408, 0.97464789,\n",
      "       0.97183099, 0.96338028, 0.97183099, 0.97183099, 0.97464789,\n",
      "       0.97464789, 0.97746479, 0.96901408, 0.97183099, 0.96619718]), 'split4_test_score': array([0.98028169, 0.98873239, 0.96901408, 0.98309859, 0.98873239,\n",
      "       0.98591549, 0.98591549, 0.90140845, 0.98873239, 0.97746479,\n",
      "       0.98873239, 0.98309859, 0.98873239, 0.93802817, 0.98309859,\n",
      "       0.98873239, 0.98873239, 0.98873239, 0.98873239, 0.94647887,\n",
      "       0.97746479, 0.94647887, 0.98873239, 0.98309859, 0.98309859,\n",
      "       0.98591549, 0.95492958, 0.98873239, 0.98873239, 0.98591549,\n",
      "       0.98309859, 0.98873239, 0.98873239, 0.98591549, 0.98309859,\n",
      "       0.98309859, 0.97464789, 0.98028169, 0.98873239, 0.98873239,\n",
      "       0.98873239, 0.97746479, 0.98873239, 0.97464789, 0.98873239,\n",
      "       0.98309859, 0.98591549, 0.98873239, 0.98873239, 0.95774648]), 'split5_test_score': array([0.98028169, 0.98028169, 0.97746479, 0.97746479, 0.98028169,\n",
      "       0.97746479, 0.97746479, 0.90704225, 0.97464789, 0.96901408,\n",
      "       0.97746479, 0.97464789, 0.97746479, 0.95211268, 0.97746479,\n",
      "       0.97464789, 0.98028169, 0.97183099, 0.97464789, 0.95211268,\n",
      "       0.96901408, 0.94647887, 0.97746479, 0.98309859, 0.97464789,\n",
      "       0.98028169, 0.95492958, 0.97746479, 0.97464789, 0.97183099,\n",
      "       0.97464789, 0.97464789, 0.97464789, 0.97183099, 0.97464789,\n",
      "       0.98028169, 0.97464789, 0.97464789, 0.97183099, 0.98028169,\n",
      "       0.98028169, 0.96619718, 0.97183099, 0.97746479, 0.97746479,\n",
      "       0.97746479, 0.97746479, 0.97183099, 0.97746479, 0.96619718]), 'split6_test_score': array([0.98028169, 0.98028169, 0.97464789, 0.97746479, 0.98309859,\n",
      "       0.97746479, 0.97183099, 0.92394366, 0.98028169, 0.98028169,\n",
      "       0.97464789, 0.97464789, 0.98028169, 0.95774648, 0.97183099,\n",
      "       0.98309859, 0.97464789, 0.98028169, 0.97746479, 0.95211268,\n",
      "       0.98028169, 0.96056338, 0.98028169, 0.97183099, 0.97746479,\n",
      "       0.97183099, 0.96338028, 0.97183099, 0.97464789, 0.97746479,\n",
      "       0.97746479, 0.98591549, 0.98309859, 0.98028169, 0.97746479,\n",
      "       0.97464789, 0.97464789, 0.98309859, 0.98028169, 0.98309859,\n",
      "       0.98028169, 0.97464789, 0.98028169, 0.97746479, 0.97746479,\n",
      "       0.98309859, 0.97746479, 0.97464789, 0.98028169, 0.96056338]), 'split7_test_score': array([0.97183099, 0.98309859, 0.97183099, 0.98028169, 0.98028169,\n",
      "       0.97746479, 0.97464789, 0.94366197, 0.97746479, 0.97464789,\n",
      "       0.98028169, 0.97746479, 0.97746479, 0.95211268, 0.97464789,\n",
      "       0.97746479, 0.97746479, 0.97746479, 0.98028169, 0.95774648,\n",
      "       0.98028169, 0.95211268, 0.97746479, 0.97746479, 0.97746479,\n",
      "       0.97746479, 0.95774648, 0.98028169, 0.98028169, 0.98309859,\n",
      "       0.98309859, 0.97183099, 0.97746479, 0.97464789, 0.98028169,\n",
      "       0.98028169, 0.97183099, 0.97183099, 0.97746479, 0.97746479,\n",
      "       0.97746479, 0.97464789, 0.97464789, 0.97464789, 0.97746479,\n",
      "       0.98028169, 0.97464789, 0.97746479, 0.98309859, 0.96901408]), 'split8_test_score': array([0.97746479, 0.97746479, 0.98309859, 0.98309859, 0.98309859,\n",
      "       0.98028169, 0.98028169, 0.91267606, 0.98028169, 0.97746479,\n",
      "       0.98028169, 0.98028169, 0.98028169, 0.94647887, 0.97746479,\n",
      "       0.98591549, 0.97746479, 0.97746479, 0.98028169, 0.95211268,\n",
      "       0.98028169, 0.95492958, 0.98028169, 0.98309859, 0.97464789,\n",
      "       0.97746479, 0.95492958, 0.97746479, 0.97746479, 0.98028169,\n",
      "       0.97183099, 0.98028169, 0.98028169, 0.98309859, 0.97746479,\n",
      "       0.97464789, 0.97746479, 0.98028169, 0.97746479, 0.97746479,\n",
      "       0.98028169, 0.97464789, 0.98028169, 0.97746479, 0.98028169,\n",
      "       0.98591549, 0.97746479, 0.98028169, 0.98309859, 0.96338028]), 'split9_test_score': array([0.98309859, 0.98309859, 0.98309859, 0.98591549, 0.9915493 ,\n",
      "       0.98591549, 0.96619718, 0.94366197, 0.98309859, 0.97464789,\n",
      "       0.98591549, 0.97464789, 0.9915493 , 0.96056338, 0.97183099,\n",
      "       0.98028169, 0.97464789, 0.98028169, 0.98591549, 0.94647887,\n",
      "       0.98591549, 0.96619718, 0.98028169, 0.97746479, 0.98028169,\n",
      "       0.97746479, 0.95774648, 0.97746479, 0.98028169, 0.97746479,\n",
      "       0.97746479, 0.98309859, 0.98309859, 0.98873239, 0.98028169,\n",
      "       0.97746479, 0.98591549, 0.98591549, 0.98591549, 0.9915493 ,\n",
      "       0.9915493 , 0.98309859, 0.98028169, 0.98309859, 0.98309859,\n",
      "       0.98873239, 0.98591549, 0.98028169, 0.98028169, 0.96338028]), 'split10_test_score': array([0.98591549, 0.98028169, 0.98309859, 0.98309859, 0.9915493 ,\n",
      "       0.98591549, 0.97746479, 0.91830986, 0.98591549, 0.97746479,\n",
      "       0.98873239, 0.98591549, 0.98591549, 0.95774648, 0.98591549,\n",
      "       0.98309859, 0.98591549, 0.98591549, 0.98591549, 0.95774648,\n",
      "       0.98591549, 0.96338028, 0.98591549, 0.98028169, 0.98028169,\n",
      "       0.98873239, 0.96056338, 0.98309859, 0.98309859, 0.9915493 ,\n",
      "       0.98309859, 0.98309859, 0.98309859, 0.98591549, 0.98591549,\n",
      "       0.98873239, 0.97746479, 0.97746479, 0.98309859, 0.9915493 ,\n",
      "       0.98309859, 0.97746479, 0.98591549, 0.97746479, 0.98873239,\n",
      "       0.98873239, 0.98591549, 0.98309859, 0.98028169, 0.97464789]), 'split11_test_score': array([0.9915493 , 0.98873239, 0.98309859, 0.98873239, 0.98591549,\n",
      "       0.98873239, 0.98591549, 0.93802817, 0.98873239, 0.98309859,\n",
      "       0.98873239, 0.98873239, 0.98591549, 0.96619718, 0.98591549,\n",
      "       0.98591549, 0.9915493 , 0.98028169, 0.98873239, 0.96901408,\n",
      "       0.9915493 , 0.96619718, 0.9915493 , 0.98309859, 0.98309859,\n",
      "       0.98873239, 0.96901408, 0.98591549, 0.98591549, 0.98591549,\n",
      "       0.98873239, 0.9943662 , 0.9915493 , 0.98591549, 0.98591549,\n",
      "       0.98591549, 0.98309859, 0.98591549, 0.98873239, 0.98873239,\n",
      "       0.98873239, 0.98028169, 0.9915493 , 0.98309859, 0.9915493 ,\n",
      "       0.98591549, 0.98591549, 0.98873239, 0.98591549, 0.96338028]), 'split12_test_score': array([0.96338028, 0.97183099, 0.96338028, 0.96619718, 0.96901408,\n",
      "       0.96619718, 0.96901408, 0.91830986, 0.97746479, 0.96619718,\n",
      "       0.97464789, 0.96619718, 0.95774648, 0.94366197, 0.97183099,\n",
      "       0.97464789, 0.96056338, 0.97183099, 0.97464789, 0.93521127,\n",
      "       0.97183099, 0.94647887, 0.96619718, 0.96056338, 0.96619718,\n",
      "       0.96338028, 0.94929577, 0.96901408, 0.96338028, 0.96619718,\n",
      "       0.96619718, 0.97464789, 0.97746479, 0.96901408, 0.96619718,\n",
      "       0.96338028, 0.96056338, 0.96901408, 0.96619718, 0.96619718,\n",
      "       0.98028169, 0.97183099, 0.97183099, 0.96338028, 0.97464789,\n",
      "       0.96901408, 0.97746479, 0.96619718, 0.96901408, 0.94929577]), 'split13_test_score': array([0.9915493 , 0.98309859, 0.98873239, 0.98873239, 0.98873239,\n",
      "       0.98591549, 0.97746479, 0.90704225, 0.9915493 , 0.98028169,\n",
      "       0.98873239, 0.98591549, 0.98591549, 0.94366197, 0.98873239,\n",
      "       0.98028169, 0.98309859, 0.98873239, 0.98591549, 0.93802817,\n",
      "       0.98591549, 0.93521127, 0.98591549, 0.98873239, 0.98591549,\n",
      "       0.98309859, 0.94647887, 0.98591549, 0.98309859, 0.98591549,\n",
      "       0.98309859, 0.98591549, 0.98873239, 0.98591549, 0.97746479,\n",
      "       0.98309859, 0.98591549, 0.98591549, 0.98591549, 0.98591549,\n",
      "       0.98873239, 0.97746479, 0.98028169, 0.98591549, 0.98591549,\n",
      "       0.98873239, 0.9915493 , 0.98309859, 0.98309859, 0.95211268]), 'split14_test_score': array([0.98309859, 0.98873239, 0.98591549, 0.98873239, 0.98873239,\n",
      "       0.98309859, 0.98309859, 0.93802817, 0.98309859, 0.97746479,\n",
      "       0.98873239, 0.98591549, 0.98591549, 0.95211268, 0.97746479,\n",
      "       0.98591549, 0.98309859, 0.98873239, 0.98591549, 0.97183099,\n",
      "       0.98873239, 0.96619718, 0.98873239, 0.97746479, 0.98309859,\n",
      "       0.98028169, 0.97746479, 0.98591549, 0.98309859, 0.97746479,\n",
      "       0.97746479, 0.9915493 , 0.9915493 , 0.98873239, 0.98309859,\n",
      "       0.98591549, 0.98873239, 0.98591549, 0.98591549, 0.98873239,\n",
      "       0.9915493 , 0.97746479, 0.9915493 , 0.98028169, 0.98309859,\n",
      "       0.98873239, 0.98309859, 0.98591549, 0.98309859, 0.97746479]), 'split15_test_score': array([0.97183099, 0.98028169, 0.97183099, 0.98028169, 0.98028169,\n",
      "       0.97746479, 0.97746479, 0.93521127, 0.98028169, 0.96901408,\n",
      "       0.98309859, 0.97464789, 0.97464789, 0.95211268, 0.97746479,\n",
      "       0.97746479, 0.97464789, 0.97464789, 0.97746479, 0.95492958,\n",
      "       0.97464789, 0.95492958, 0.97464789, 0.97183099, 0.96901408,\n",
      "       0.97464789, 0.96056338, 0.97464789, 0.97464789, 0.96901408,\n",
      "       0.97183099, 0.97464789, 0.97746479, 0.98028169, 0.97183099,\n",
      "       0.97464789, 0.97183099, 0.97464789, 0.97464789, 0.97746479,\n",
      "       0.97746479, 0.97183099, 0.97183099, 0.97746479, 0.97746479,\n",
      "       0.98028169, 0.97746479, 0.98309859, 0.97746479, 0.96338028]), 'split16_test_score': array([0.98591549, 0.98309859, 0.97746479, 0.98591549, 0.98591549,\n",
      "       0.98873239, 0.98591549, 0.91830986, 0.98309859, 0.98028169,\n",
      "       0.98591549, 0.98028169, 0.98591549, 0.94366197, 0.98873239,\n",
      "       0.98028169, 0.98028169, 0.98591549, 0.98591549, 0.95492958,\n",
      "       0.98591549, 0.94366197, 0.98591549, 0.98309859, 0.98028169,\n",
      "       0.98591549, 0.95211268, 0.98591549, 0.98591549, 0.98309859,\n",
      "       0.98591549, 0.98028169, 0.98309859, 0.98591549, 0.98028169,\n",
      "       0.98028169, 0.98028169, 0.98591549, 0.98873239, 0.98591549,\n",
      "       0.98309859, 0.98028169, 0.98028169, 0.98591549, 0.98873239,\n",
      "       0.98591549, 0.98591549, 0.98873239, 0.98309859, 0.96338028]), 'split17_test_score': array([0.98309859, 0.98873239, 0.98591549, 0.98873239, 0.9915493 ,\n",
      "       0.9915493 , 0.98591549, 0.95492958, 0.98591549, 0.98309859,\n",
      "       0.9915493 , 0.98873239, 0.98309859, 0.96901408, 0.98028169,\n",
      "       0.98591549, 0.98309859, 0.98591549, 0.9915493 , 0.96901408,\n",
      "       0.98591549, 0.97464789, 0.98873239, 0.98309859, 0.98591549,\n",
      "       0.98591549, 0.97183099, 0.98309859, 0.98591549, 0.98309859,\n",
      "       0.98028169, 0.98309859, 0.98873239, 0.98873239, 0.98309859,\n",
      "       0.98309859, 0.98309859, 0.98309859, 0.98873239, 0.98591549,\n",
      "       0.98873239, 0.98591549, 0.98309859, 0.98873239, 0.98873239,\n",
      "       0.9915493 , 0.9915493 , 0.98873239, 0.98873239, 0.98591549]), 'split18_test_score': array([0.98587571, 0.98305085, 0.98022599, 0.98305085, 0.98305085,\n",
      "       0.98022599, 0.97457627, 0.90677966, 0.98022599, 0.97175141,\n",
      "       0.98305085, 0.98305085, 0.98022599, 0.93502825, 0.98587571,\n",
      "       0.98022599, 0.98022599, 0.98022599, 0.98305085, 0.94350282,\n",
      "       0.98022599, 0.93502825, 0.98022599, 0.97740113, 0.97457627,\n",
      "       0.98022599, 0.94350282, 0.98022599, 0.98305085, 0.98022599,\n",
      "       0.98022599, 0.98305085, 0.97740113, 0.98305085, 0.98305085,\n",
      "       0.98022599, 0.98022599, 0.97740113, 0.98022599, 0.98587571,\n",
      "       0.98022599, 0.98305085, 0.98305085, 0.98022599, 0.98305085,\n",
      "       0.98587571, 0.98022599, 0.98305085, 0.98305085, 0.95762712]), 'split19_test_score': array([0.97457627, 0.97457627, 0.97457627, 0.96892655, 0.97457627,\n",
      "       0.97740113, 0.96327684, 0.92090395, 0.97457627, 0.97457627,\n",
      "       0.98022599, 0.97175141, 0.97175141, 0.93785311, 0.97175141,\n",
      "       0.97740113, 0.97175141, 0.96892655, 0.97740113, 0.93785311,\n",
      "       0.96892655, 0.94067797, 0.97175141, 0.97457627, 0.96610169,\n",
      "       0.96327684, 0.94632768, 0.97175141, 0.97175141, 0.97175141,\n",
      "       0.97740113, 0.97175141, 0.97740113, 0.97740113, 0.96892655,\n",
      "       0.97175141, 0.96892655, 0.96892655, 0.97175141, 0.98022599,\n",
      "       0.98022599, 0.96892655, 0.96892655, 0.96610169, 0.96892655,\n",
      "       0.97457627, 0.96892655, 0.96892655, 0.97175141, 0.9519774 ]), 'mean_test_score': array([0.9808395 , 0.98252924, 0.97844434, 0.9823876 , 0.98421938,\n",
      "       0.9823884 , 0.97801942, 0.92434193, 0.982388  , 0.97717554,\n",
      "       0.98407933, 0.98041617, 0.98126084, 0.95181308, 0.97971234,\n",
      "       0.98196586, 0.97914817, 0.98083791, 0.98309302, 0.95336357,\n",
      "       0.98126044, 0.95392616, 0.98196507, 0.97900732, 0.97844235,\n",
      "       0.97971035, 0.95759012, 0.98069746, 0.97985279, 0.98013408,\n",
      "       0.97943065, 0.98210631, 0.98266969, 0.98281133, 0.97914817,\n",
      "       0.98013408, 0.97745763, 0.98041498, 0.98112   , 0.98379804,\n",
      "       0.98393809, 0.97689464, 0.98083831, 0.97928822, 0.9823876 ,\n",
      "       0.98407894, 0.98266889, 0.98154253, 0.98168377, 0.96393093]), 'std_test_score': array([0.00699312, 0.00588646, 0.0073616 , 0.00629998, 0.00587468,\n",
      "       0.00616701, 0.00733598, 0.01419523, 0.0054155 , 0.00597404,\n",
      "       0.00592942, 0.00681583, 0.0080849 , 0.00945202, 0.00687973,\n",
      "       0.00522825, 0.00709647, 0.00634492, 0.00591184, 0.01154627,\n",
      "       0.00725961, 0.01094562, 0.00698649, 0.0067563 , 0.00681071,\n",
      "       0.00785758, 0.00881692, 0.00638434, 0.00691929, 0.00732166,\n",
      "       0.00667257, 0.0068638 , 0.00625828, 0.00683884, 0.00657544,\n",
      "       0.00651904, 0.00696146, 0.00682046, 0.00741009, 0.00659957,\n",
      "       0.00550211, 0.00627672, 0.00694111, 0.00703811, 0.00597681,\n",
      "       0.00612968, 0.00651205, 0.00769404, 0.0058134 , 0.00987511]), 'rank_test_score': array([23, 10, 39, 13,  1, 11, 41, 50, 12, 43,  2, 27, 20, 49, 32, 16, 36,\n",
      "       25,  6, 48, 21, 47, 17, 38, 40, 33, 46, 26, 31, 29, 34, 15,  8,  7,\n",
      "       36, 29, 42, 28, 22,  5,  4, 44, 24, 35, 13,  3,  9, 19, 18, 45])}\n",
      "RandomGrid best score: 0.9842193841012173\n",
      "Train: 1.000\n",
      "Test: 0.979\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.935717709073729,\n              enable_categorical=False, gamma=0, gpu_id=-1,\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.32342417815924285, max_delta_step=0, max_depth=8,\n              min_child_weight=3, missing=nan, monotone_constraints='()',\n              n_estimators=151, n_jobs=14, num_parallel_tree=1,\n              objective='multi:softprob', predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.9055141763852883, tree_method='exact',\n              validate_parameters=1, verbosity=None)",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.935717709073729,\n              enable_categorical=False, gamma=0, gpu_id=-1,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.32342417815924285, max_delta_step=0, max_depth=8,\n              min_child_weight=3, missing=nan, monotone_constraints=&#x27;()&#x27;,\n              n_estimators=151, n_jobs=14, num_parallel_tree=1,\n              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.9055141763852883, tree_method=&#x27;exact&#x27;,\n              validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.935717709073729,\n              enable_categorical=False, gamma=0, gpu_id=-1,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.32342417815924285, max_delta_step=0, max_depth=8,\n              min_child_weight=3, missing=nan, monotone_constraints=&#x27;()&#x27;,\n              n_estimators=151, n_jobs=14, num_parallel_tree=1,\n              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.9055141763852883, tree_method=&#x27;exact&#x27;,\n              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "clf_xgb = XGBClassifier(objective='multi:softmax')\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': stats.randint(150, 500),\n",
    "    'learning_rate': stats.uniform(0.01, 1),\n",
    "    'subsample': stats.uniform(0.3, 0.7),\n",
    "    'max_depth': [3, 5, 8],\n",
    "    'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, param_distributions=param_dist, verbose=3,\n",
    "                         cv=20, n_iter=50, scoring='accuracy', error_score=0,\n",
    "                         random_state=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Validation results:\", clf.cv_results_)\n",
    "\n",
    "print(\"RandomGrid best score:\", clf.best_score_)\n",
    "\n",
    "print(f'Train: {clf.score(X_train, y_train):.3f}')\n",
    "print(f'Test: {clf.score(X_test, y_test):.3f}')\n",
    "\n",
    "clf.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_features, train_target, val_features, val_target, **params):\n",
    "    model = XGBClassifier(random_state=22, n_jobs=-1, **params)\n",
    "\n",
    "    model.fit(train_features, train_target)\n",
    "    train_accuracy = model.score(train_features, train_target)\n",
    "\n",
    "    val_accuracy = model.score(val_features, val_target)\n",
    "\n",
    "    return model, train_accuracy, val_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_params_kfold(n_splits, **params):\n",
    "    train_accuracys, val_accuracys, models = [], [], []\n",
    "\n",
    "    kfold = KFold(n_splits)\n",
    "\n",
    "    kfold_features = features.copy()\n",
    "    kfold_target = target_num.copy()\n",
    "\n",
    "    kfold_features = decision_tree_data_preparation(kfold_features)\n",
    "\n",
    "    for train_idxs, val_idxs in kfold.split(kfold_features):\n",
    "        X_train, train_targets = kfold_features.iloc[train_idxs], kfold_target.iloc[train_idxs]\n",
    "        X_val, val_targets = kfold_features.iloc[val_idxs], kfold_target.iloc[val_idxs]\n",
    "\n",
    "        model, train_acc, val_acc = train_and_evaluate(X_train, train_targets, X_val, val_targets, **params)\n",
    "\n",
    "        models.append(model)\n",
    "        train_accuracys.append(train_acc)\n",
    "        val_accuracys.append(val_acc)\n",
    "\n",
    "    print(\"Train accuracys:\", train_accuracys)\n",
    "    print(\"Validation accuracys:\", val_accuracys)\n",
    "    print(f'Train accuracy: {np.mean(train_accuracys)}, Validation accuracy: {np.mean(val_accuracys)}')\n",
    "\n",
    "    return models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% % time\n",
    "test_params_kfold(5, n_estimators=500, max_depth=6, learning_rate=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtenção das previsões do dataset de submissão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "test_data = test_df.copy()\n",
    "\n",
    "test_data_prepared = decision_tree_data_preparation(test_data)\n",
    "\n",
    "predictions = boost_model.predict(test_data_prepared)  #RF_Model.predict(test_data_prepared)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df = predictions_df[0].map(\n",
    "    {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very_High'})\n",
    "predictions_df.index += 1\n",
    "predictions_df.to_csv(\"../submission_v2.csv\", header=['Incidents'], index_label='RowId')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
