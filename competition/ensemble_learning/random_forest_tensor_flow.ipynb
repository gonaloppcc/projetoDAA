{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementação do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from pandas import DataFrame\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "TRAINING_DATASET_SOURCE = '../datasets/training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = '../datasets/test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Definição dos dados de teste e de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13) (1206, 12)\n",
      "None         2028\n",
      "High         1073\n",
      "Low           718\n",
      "Very_High     603\n",
      "Medium        578\n",
      "Name: incidents, dtype: int64\n",
      "Max value count: 2028\n",
      "None         2028\n",
      "High         2028\n",
      "Low          2028\n",
      "Very_High    2028\n",
      "Medium       2028\n",
      "Name: incidents, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df['incidents'].value_counts())\n",
    "\n",
    "incidents_count = train_df['incidents'].value_counts()\n",
    "\n",
    "max_count = incidents_count.max()\n",
    "print('Max value count:', max_count)\n",
    "\n",
    "df_classes = []\n",
    "for category, counts in zip(incidents_count.index, incidents_count):\n",
    "    #print(category, counts)\n",
    "    df_classes.append(train_df[train_df['incidents'] == category])\n",
    "\n",
    "df_classes_over = []\n",
    "\n",
    "for category in df_classes:\n",
    "    df_classes_over.append(category.sample(max_count, replace=True))\n",
    "\n",
    "df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "print(df_test_over['incidents'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>magnitude_of_delay</th>\n",
       "      <th>delay_in_seconds</th>\n",
       "      <th>affected_roads</th>\n",
       "      <th>record_date</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>avg_atm_pressure</th>\n",
       "      <th>avg_humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>avg_precipitation</th>\n",
       "      <th>avg_rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>N101,N101,N101,N101,N101</td>\n",
       "      <td>2021-06-27 12:00</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>N101,N101,N101,N101,N101</td>\n",
       "      <td>2021-11-24 06:00</td>\n",
       "      <td>DARK</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>N101,N101,N101,N101,N101</td>\n",
       "      <td>2021-10-10 13:00</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>N101,N101,N101,N101,N101</td>\n",
       "      <td>2021-07-16 05:00</td>\n",
       "      <td>DARK</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>2021-03-14 21:00</td>\n",
       "      <td>DARK</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city_name magnitude_of_delay  delay_in_seconds  \\\n",
       "1763  Guimaraes          UNDEFINED                 0   \n",
       "2455  Guimaraes          UNDEFINED                 0   \n",
       "2935  Guimaraes          UNDEFINED                 0   \n",
       "4125  Guimaraes          UNDEFINED                 0   \n",
       "3678  Guimaraes          UNDEFINED                 0   \n",
       "\n",
       "                affected_roads       record_date luminosity  avg_temperature  \\\n",
       "1763  N101,N101,N101,N101,N101  2021-06-27 12:00      LIGHT             18.0   \n",
       "2455  N101,N101,N101,N101,N101  2021-11-24 06:00       DARK              6.0   \n",
       "2935  N101,N101,N101,N101,N101  2021-10-10 13:00      LIGHT             23.0   \n",
       "4125  N101,N101,N101,N101,N101  2021-07-16 05:00       DARK             23.0   \n",
       "3678                         ,  2021-03-14 21:00       DARK             11.0   \n",
       "\n",
       "      avg_atm_pressure  avg_humidity  avg_wind_speed  avg_precipitation  \\\n",
       "1763            1017.0          69.0             4.0                0.0   \n",
       "2455            1016.0          79.0             1.0                0.0   \n",
       "2935            1019.0          25.0             4.0                0.0   \n",
       "4125            1016.0          40.0             3.0                0.0   \n",
       "3678            1028.0          84.0             1.0                0.0   \n",
       "\n",
       "       avg_rain  \n",
       "1763  Sem Chuva  \n",
       "2455  Sem Chuva  \n",
       "2935  Sem Chuva  \n",
       "4125  Sem Chuva  \n",
       "3678  Sem Chuva  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_test_over.drop(['incidents'], axis=1)\n",
    "target = df_test_over['incidents']\n",
    "\n",
    "all_features = features.columns.tolist()\n",
    "\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtenção das features numericas e categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_to_numerical = {\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 1,\n",
    "        'DARK': 2\n",
    "    },\n",
    "    'avg_rain': {\n",
    "        'Sem Chuva': 0,\n",
    "        'chuva fraca': 1,\n",
    "        'chuva moderada': 2,\n",
    "        'chuva forte': 3,\n",
    "    }\n",
    "}\n",
    "\n",
    "def decision_tree_data_preparation(df: DataFrame) -> DataFrame:\n",
    "    dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay']\n",
    "\n",
    "    numerical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                          dtype.kind in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    numerical_features = ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "    #assert numerical_features == ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "\n",
    "\n",
    "    categorical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                            dtype.kind not in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    prep_df = df.drop(dropped_columns, axis=1)\n",
    "    prep_df.drop_duplicates()\n",
    "\n",
    "    ### Converter as features categoricas em numericas\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "    record_date = pd.DatetimeIndex(prep_df['record_date'])\n",
    "\n",
    "    prep_df['hour'] = record_date.hour\n",
    "    prep_df['day'] = record_date.day\n",
    "    prep_df['month'] = record_date.month\n",
    "    prep_df['weekday'] = record_date.weekday\n",
    "\n",
    "    prep_df.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "    #train_df['affected_roads'] = train_df['affected_roads'].fillna(train_df['affected_roads'].mode().iloc[0])\n",
    "\n",
    "    num_affected_roads = []\n",
    "    for line in df['affected_roads']:\n",
    "        unique_roads = set(str(line).split(','))\n",
    "        valid_roads = [elem for elem in unique_roads if elem != '']\n",
    "        count = len(valid_roads)\n",
    "        num_affected_roads.append(count)\n",
    "\n",
    "    prep_df['num_affected_roads'] = num_affected_roads\n",
    "\n",
    "    ### Ao analisar o resultado pós-tratamento, verificámos que a feature 'affected_roads' tinha alta correlação com 'delay_in_minutes'\n",
    "    prep_df.drop(columns=['affected_roads'], inplace=True)\n",
    "\n",
    "    ### Converter a feature 'delay_in_seconds' para 'delay_in_minutes' de modo a reduzir o intervalo de valores\n",
    "    delay_in_minutes = prep_df['delay_in_seconds'].map(lambda seconds : seconds / 60)\n",
    "\n",
    "    prep_df.drop(columns=['delay_in_seconds'], inplace=True)\n",
    "    prep_df['delay_in_minutes'] = delay_in_minutes\n",
    "\n",
    "    ### Limites superior e inferior (sem outliers) dos diagramas de caixa\n",
    "    #numerical_features.remove('delay_in_seconds')\n",
    "    #numerical_features.append('delay_in_minutes')\n",
    "\n",
    "    return prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Divisão dos dados em dados de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1763    0\n",
       "2455    0\n",
       "2935    0\n",
       "4125    0\n",
       "3678    0\n",
       "       ..\n",
       "3556    2\n",
       "3505    2\n",
       "2507    2\n",
       "171     2\n",
       "4483    2\n",
       "Name: incidents, Length: 10140, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_num = target.map({'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4})\n",
    "target_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(decision_tree_data_preparation(features), target_num, test_size=0.3,\n",
    "                                                    random_state=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_estimators = [100, 200] #[int(x) for x in np.linspace(start=10, stop=500, num=5)]\n",
    "\n",
    "max_features = [int(x) for x in np.linspace(start=6, stop=12, num=3)]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(start=10, stop=500, num=5)]\n",
    "\n",
    "min_samples_split = [int(x) for x in np.linspace(start=2, stop=30, num=2)]  #[2, 5, 10, 20]\n",
    "\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start=2, stop=30, num=2)]  # [1, 2, 5, 10]\n",
    "\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(start=20, stop=200, num=5)]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterions = [\"gini\", \"entropy\", \"log_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtenção das previsões do dataset de submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_df.copy()\n",
    "\n",
    "test_data_prepared = decision_tree_data_preparation(test_data)\n",
    "\n",
    "predictions = rf_RandomGrid.predict(test_data_prepared) #RF_Model.predict(test_data_prepared)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.index += 1\n",
    "predictions_df.to_csv(\"../submission_v2.csv\", header=['Incidents'], index_label='RowId')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.1 (main, Dec 23 2022, 09:25:23) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
