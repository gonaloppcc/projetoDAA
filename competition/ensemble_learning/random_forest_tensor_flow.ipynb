{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementação do Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from pandas import DataFrame\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "TRAINING_DATASET_SOURCE = '../training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = '../test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definição dos dados de teste e de treino"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13) (1206, 12)\n",
      "None         2028\n",
      "High         1073\n",
      "Low           718\n",
      "Very_High     603\n",
      "Medium        578\n",
      "Name: incidents, dtype: int64\n",
      "Max value count: 2028\n",
      "None         2028\n",
      "High         2028\n",
      "Low          2028\n",
      "Very_High    2028\n",
      "Medium       2028\n",
      "Name: incidents, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df['incidents'].value_counts())\n",
    "\n",
    "incidents_count = train_df['incidents'].value_counts()\n",
    "\n",
    "max_count = incidents_count.max()\n",
    "print('Max value count:', max_count)\n",
    "\n",
    "df_classes = []\n",
    "for category, counts in zip(incidents_count.index, incidents_count):\n",
    "    #print(category, counts)\n",
    "    df_classes.append(train_df[train_df['incidents'] == category])\n",
    "\n",
    "df_classes_over = []\n",
    "\n",
    "for category in df_classes:\n",
    "    df_classes_over.append(category.sample(max_count, replace=True))\n",
    "\n",
    "df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "print(df_test_over['incidents'].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      city_name magnitude_of_delay  delay_in_seconds  \\\n1763  Guimaraes          UNDEFINED                 0   \n2455  Guimaraes          UNDEFINED                 0   \n2935  Guimaraes          UNDEFINED                 0   \n4125  Guimaraes          UNDEFINED                 0   \n3678  Guimaraes          UNDEFINED                 0   \n\n                affected_roads       record_date luminosity  avg_temperature  \\\n1763  N101,N101,N101,N101,N101  2021-06-27 12:00      LIGHT             18.0   \n2455  N101,N101,N101,N101,N101  2021-11-24 06:00       DARK              6.0   \n2935  N101,N101,N101,N101,N101  2021-10-10 13:00      LIGHT             23.0   \n4125  N101,N101,N101,N101,N101  2021-07-16 05:00       DARK             23.0   \n3678                         ,  2021-03-14 21:00       DARK             11.0   \n\n      avg_atm_pressure  avg_humidity  avg_wind_speed  avg_precipitation  \\\n1763            1017.0          69.0             4.0                0.0   \n2455            1016.0          79.0             1.0                0.0   \n2935            1019.0          25.0             4.0                0.0   \n4125            1016.0          40.0             3.0                0.0   \n3678            1028.0          84.0             1.0                0.0   \n\n       avg_rain  \n1763  Sem Chuva  \n2455  Sem Chuva  \n2935  Sem Chuva  \n4125  Sem Chuva  \n3678  Sem Chuva  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city_name</th>\n      <th>magnitude_of_delay</th>\n      <th>delay_in_seconds</th>\n      <th>affected_roads</th>\n      <th>record_date</th>\n      <th>luminosity</th>\n      <th>avg_temperature</th>\n      <th>avg_atm_pressure</th>\n      <th>avg_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>avg_precipitation</th>\n      <th>avg_rain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1763</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-06-27 12:00</td>\n      <td>LIGHT</td>\n      <td>18.0</td>\n      <td>1017.0</td>\n      <td>69.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2455</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-11-24 06:00</td>\n      <td>DARK</td>\n      <td>6.0</td>\n      <td>1016.0</td>\n      <td>79.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2935</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-10-10 13:00</td>\n      <td>LIGHT</td>\n      <td>23.0</td>\n      <td>1019.0</td>\n      <td>25.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>4125</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>N101,N101,N101,N101,N101</td>\n      <td>2021-07-16 05:00</td>\n      <td>DARK</td>\n      <td>23.0</td>\n      <td>1016.0</td>\n      <td>40.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>3678</th>\n      <td>Guimaraes</td>\n      <td>UNDEFINED</td>\n      <td>0</td>\n      <td>,</td>\n      <td>2021-03-14 21:00</td>\n      <td>DARK</td>\n      <td>11.0</td>\n      <td>1028.0</td>\n      <td>84.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_test_over.drop(['incidents'], axis=1)\n",
    "target = df_test_over['incidents']\n",
    "\n",
    "all_features = features.columns.tolist()\n",
    "\n",
    "features[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtenção das features numericas e categoricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_to_numerical = {\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 1,\n",
    "        'DARK': 2\n",
    "    },\n",
    "    'avg_rain': {\n",
    "        'Sem Chuva': 0,\n",
    "        'chuva fraca': 1,\n",
    "        'chuva moderada': 2,\n",
    "        'chuva forte': 3,\n",
    "    }\n",
    "}\n",
    "\n",
    "def decision_tree_data_preparation(df: DataFrame) -> DataFrame:\n",
    "    dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay']\n",
    "\n",
    "    numerical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                          dtype.kind in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    numerical_features = ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "    #assert numerical_features == ['avg_temperature', 'avg_atm_pressure', 'avg_humidity', 'avg_wind_speed', 'luminosity']\n",
    "\n",
    "\n",
    "    categorical_features = [column for column, dtype in zip(features.columns, features.dtypes) if\n",
    "                            dtype.kind not in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "    prep_df = df.drop(dropped_columns, axis=1)\n",
    "    prep_df.drop_duplicates()\n",
    "\n",
    "    ### Converter as features categoricas em numericas\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "    record_date = pd.DatetimeIndex(prep_df['record_date'])\n",
    "\n",
    "    prep_df['hour'] = record_date.hour\n",
    "    prep_df['day'] = record_date.day\n",
    "    prep_df['month'] = record_date.month\n",
    "    prep_df['weekday'] = record_date.weekday\n",
    "\n",
    "    prep_df.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "    #train_df['affected_roads'] = train_df['affected_roads'].fillna(train_df['affected_roads'].mode().iloc[0])\n",
    "\n",
    "    num_affected_roads = []\n",
    "    for line in df['affected_roads']:\n",
    "        unique_roads = set(str(line).split(','))\n",
    "        valid_roads = [elem for elem in unique_roads if elem != '']\n",
    "        count = len(valid_roads)\n",
    "        num_affected_roads.append(count)\n",
    "\n",
    "    prep_df['num_affected_roads'] = num_affected_roads\n",
    "\n",
    "    ### Ao analisar o resultado pós-tratamento, verificámos que a feature 'affected_roads' tinha alta correlação com 'delay_in_minutes'\n",
    "    prep_df.drop(columns=['affected_roads'], inplace=True)\n",
    "\n",
    "    ### Converter a feature 'delay_in_seconds' para 'delay_in_minutes' de modo a reduzir o intervalo de valores\n",
    "    delay_in_minutes = prep_df['delay_in_seconds'].map(lambda seconds : seconds / 60)\n",
    "\n",
    "    prep_df.drop(columns=['delay_in_seconds'], inplace=True)\n",
    "    prep_df['delay_in_minutes'] = delay_in_minutes\n",
    "\n",
    "    ### Limites superior e inferior (sem outliers) dos diagramas de caixa\n",
    "    #numerical_features.remove('delay_in_seconds')\n",
    "    #numerical_features.append('delay_in_minutes')\n",
    "\n",
    "    return prep_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Divisão dos dados em dados de teste e treino"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1763    0\n2455    0\n2935    0\n4125    0\n3678    0\n       ..\n3556    2\n3505    2\n2507    2\n171     2\n4483    2\nName: incidents, Length: 10140, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_num = target.map({'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4})\n",
    "target_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(decision_tree_data_preparation(features), target_num, test_size=0.3,\n",
    "                                                    random_state=2000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_estimators = [100, 200] #[int(x) for x in np.linspace(start=10, stop=500, num=5)]\n",
    "\n",
    "max_features = [int(x) for x in np.linspace(start=6, stop=12, num=3)]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(start=10, stop=500, num=5)]\n",
    "\n",
    "min_samples_split = [int(x) for x in np.linspace(start=2, stop=30, num=2)]  #[2, 5, 10, 20]\n",
    "\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start=2, stop=30, num=2)]  # [1, 2, 5, 10]\n",
    "\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(start=20, stop=200, num=5)]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterions = [\"gini\", \"entropy\", \"log_loss\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtenção das previsões do dataset de submissão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "test_data = test_df.copy()\n",
    "\n",
    "test_data_prepared = decision_tree_data_preparation(test_data)\n",
    "\n",
    "predictions = rf_RandomGrid.predict(test_data_prepared) #RF_Model.predict(test_data_prepared)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.index += 1\n",
    "predictions_df.to_csv(\"../submission_v2.csv\", header=['Incidents'], index_label='RowId')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
